{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I-BPnP8QhvN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers, models\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и подготовка данных\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = \"/content/drive/My Drive/Project/DataSetCyrillic\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPwTTghFWhBZ",
        "outputId": "7b915ac0-933d-4cc2-a64f-2af5e0b44c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# размер изображений 28 на 28 => входной вектор длины 784\n",
        "labels = []\n",
        "images = []\n",
        "\n",
        "for folder in os.listdir(data_path):\n",
        "    for filename in os.listdir(os.path.join(data_path, folder)):\n",
        "        img_path = os.path.join(data_path, folder, filename)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = img / 255  # Нормализация значений пикселей\n",
        "        label = ord(folder[0]) - ord('А')\n",
        "        images.append(img)\n",
        "        labels.append(label)"
      ],
      "metadata": {
        "id": "1RpRrDgrX7cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование в массив numpy\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "3QKnJEGehbFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных на обучающий и тестовый наборы\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "ztsqu6VShjCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "QoNpR7cPmDMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))  # Добавлен сверточный слой\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))  # скрытый слой 128 нейронов\n",
        "model.add(Dropout(0.5))  # Добавлен слой Dropout\n",
        "model.add(layers.Dense(66, activation='softmax'))  # выходной 63 нейрона (33 буквы, из них все, кроме ъ, ы, ь в двух вариантах (большая и маленькая))\n",
        "# 66 для краткости\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdXZc02CnVay",
        "outputId": "8591c31c-083d-4eb3-e42d-d206d015bdd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 66)                8514      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232258 (907.26 KB)\n",
            "Trainable params: 232258 (907.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-AcyW3wUoEvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CouuJXU6pBLP",
        "outputId": "7dabc73b-fa83-4348-90ae-8ab35a2dae83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "493/493 [==============================] - 20s 39ms/step - loss: 3.9605 - accuracy: 0.0502 - val_loss: 3.5046 - val_accuracy: 0.1162\n",
            "Epoch 2/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 3.2682 - accuracy: 0.1403 - val_loss: 2.7437 - val_accuracy: 0.3037\n",
            "Epoch 3/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 2.7947 - accuracy: 0.2409 - val_loss: 2.3422 - val_accuracy: 0.4051\n",
            "Epoch 4/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 2.4945 - accuracy: 0.3060 - val_loss: 2.0710 - val_accuracy: 0.4559\n",
            "Epoch 5/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 2.2739 - accuracy: 0.3583 - val_loss: 1.9140 - val_accuracy: 0.4977\n",
            "Epoch 6/100\n",
            "493/493 [==============================] - 19s 39ms/step - loss: 2.1223 - accuracy: 0.3949 - val_loss: 1.7014 - val_accuracy: 0.5406\n",
            "Epoch 7/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.9863 - accuracy: 0.4258 - val_loss: 1.6075 - val_accuracy: 0.5794\n",
            "Epoch 8/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.8999 - accuracy: 0.4443 - val_loss: 1.4720 - val_accuracy: 0.6068\n",
            "Epoch 9/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.8168 - accuracy: 0.4634 - val_loss: 1.4481 - val_accuracy: 0.6101\n",
            "Epoch 10/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 1.7080 - accuracy: 0.4913 - val_loss: 1.3638 - val_accuracy: 0.6337\n",
            "Epoch 11/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.6592 - accuracy: 0.4997 - val_loss: 1.2966 - val_accuracy: 0.6423\n",
            "Epoch 12/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 1.5973 - accuracy: 0.5159 - val_loss: 1.2440 - val_accuracy: 0.6555\n",
            "Epoch 13/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.5534 - accuracy: 0.5253 - val_loss: 1.2055 - val_accuracy: 0.6672\n",
            "Epoch 14/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 1.4916 - accuracy: 0.5399 - val_loss: 1.1616 - val_accuracy: 0.6783\n",
            "Epoch 15/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 1.4450 - accuracy: 0.5493 - val_loss: 1.1755 - val_accuracy: 0.6702\n",
            "Epoch 16/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 1.4058 - accuracy: 0.5644 - val_loss: 1.1005 - val_accuracy: 0.6956\n",
            "Epoch 17/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 1.3718 - accuracy: 0.5711 - val_loss: 1.0599 - val_accuracy: 0.6961\n",
            "Epoch 18/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 1.3450 - accuracy: 0.5804 - val_loss: 1.0698 - val_accuracy: 0.6963\n",
            "Epoch 19/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.2963 - accuracy: 0.5914 - val_loss: 1.0531 - val_accuracy: 0.6966\n",
            "Epoch 20/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 1.2717 - accuracy: 0.5945 - val_loss: 1.0369 - val_accuracy: 0.7027\n",
            "Epoch 21/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 1.2270 - accuracy: 0.6076 - val_loss: 0.9796 - val_accuracy: 0.7227\n",
            "Epoch 22/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.2023 - accuracy: 0.6151 - val_loss: 0.9797 - val_accuracy: 0.7171\n",
            "Epoch 23/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.1864 - accuracy: 0.6122 - val_loss: 0.9845 - val_accuracy: 0.7075\n",
            "Epoch 24/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 1.1706 - accuracy: 0.6250 - val_loss: 0.9704 - val_accuracy: 0.7164\n",
            "Epoch 25/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.1439 - accuracy: 0.6261 - val_loss: 0.9465 - val_accuracy: 0.7273\n",
            "Epoch 26/100\n",
            "493/493 [==============================] - 19s 39ms/step - loss: 1.1272 - accuracy: 0.6353 - val_loss: 0.9493 - val_accuracy: 0.7321\n",
            "Epoch 27/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.0901 - accuracy: 0.6490 - val_loss: 0.9080 - val_accuracy: 0.7382\n",
            "Epoch 28/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.0803 - accuracy: 0.6453 - val_loss: 0.9256 - val_accuracy: 0.7385\n",
            "Epoch 29/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.0472 - accuracy: 0.6547 - val_loss: 0.9195 - val_accuracy: 0.7319\n",
            "Epoch 30/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.0478 - accuracy: 0.6576 - val_loss: 0.9158 - val_accuracy: 0.7359\n",
            "Epoch 31/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 1.0243 - accuracy: 0.6665 - val_loss: 0.9200 - val_accuracy: 0.7440\n",
            "Epoch 32/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 1.0062 - accuracy: 0.6659 - val_loss: 0.8890 - val_accuracy: 0.7484\n",
            "Epoch 33/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.9900 - accuracy: 0.6725 - val_loss: 0.8746 - val_accuracy: 0.7522\n",
            "Epoch 34/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.9794 - accuracy: 0.6706 - val_loss: 0.8648 - val_accuracy: 0.7504\n",
            "Epoch 35/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.9669 - accuracy: 0.6808 - val_loss: 0.8603 - val_accuracy: 0.7603\n",
            "Epoch 36/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.9505 - accuracy: 0.6812 - val_loss: 0.9117 - val_accuracy: 0.7466\n",
            "Epoch 37/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.9371 - accuracy: 0.6896 - val_loss: 0.9288 - val_accuracy: 0.7435\n",
            "Epoch 38/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.9203 - accuracy: 0.6960 - val_loss: 0.8574 - val_accuracy: 0.7514\n",
            "Epoch 39/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.9124 - accuracy: 0.6912 - val_loss: 0.8622 - val_accuracy: 0.7628\n",
            "Epoch 40/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.9056 - accuracy: 0.7015 - val_loss: 0.8588 - val_accuracy: 0.7600\n",
            "Epoch 41/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.8986 - accuracy: 0.6984 - val_loss: 0.8731 - val_accuracy: 0.7707\n",
            "Epoch 42/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.8761 - accuracy: 0.7033 - val_loss: 0.8569 - val_accuracy: 0.7633\n",
            "Epoch 43/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.8685 - accuracy: 0.7104 - val_loss: 0.8642 - val_accuracy: 0.7661\n",
            "Epoch 44/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.8535 - accuracy: 0.7122 - val_loss: 0.8616 - val_accuracy: 0.7608\n",
            "Epoch 45/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.8461 - accuracy: 0.7156 - val_loss: 0.8603 - val_accuracy: 0.7745\n",
            "Epoch 46/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.8403 - accuracy: 0.7184 - val_loss: 0.8882 - val_accuracy: 0.7593\n",
            "Epoch 47/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 0.8292 - accuracy: 0.7192 - val_loss: 0.8906 - val_accuracy: 0.7648\n",
            "Epoch 48/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.8276 - accuracy: 0.7188 - val_loss: 0.8625 - val_accuracy: 0.7684\n",
            "Epoch 49/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.7997 - accuracy: 0.7266 - val_loss: 0.8515 - val_accuracy: 0.7694\n",
            "Epoch 50/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7962 - accuracy: 0.7272 - val_loss: 0.8746 - val_accuracy: 0.7750\n",
            "Epoch 51/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7872 - accuracy: 0.7327 - val_loss: 0.8755 - val_accuracy: 0.7684\n",
            "Epoch 52/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.7823 - accuracy: 0.7351 - val_loss: 0.8757 - val_accuracy: 0.7699\n",
            "Epoch 53/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7724 - accuracy: 0.7337 - val_loss: 0.8778 - val_accuracy: 0.7730\n",
            "Epoch 54/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.7700 - accuracy: 0.7375 - val_loss: 0.8555 - val_accuracy: 0.7694\n",
            "Epoch 55/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7666 - accuracy: 0.7350 - val_loss: 0.8767 - val_accuracy: 0.7760\n",
            "Epoch 56/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.7552 - accuracy: 0.7403 - val_loss: 0.8623 - val_accuracy: 0.7707\n",
            "Epoch 57/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7481 - accuracy: 0.7450 - val_loss: 0.8765 - val_accuracy: 0.7725\n",
            "Epoch 58/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7359 - accuracy: 0.7481 - val_loss: 0.8575 - val_accuracy: 0.7768\n",
            "Epoch 59/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7502 - accuracy: 0.7429 - val_loss: 0.8776 - val_accuracy: 0.7727\n",
            "Epoch 60/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7177 - accuracy: 0.7560 - val_loss: 0.9367 - val_accuracy: 0.7661\n",
            "Epoch 61/100\n",
            "493/493 [==============================] - 19s 39ms/step - loss: 0.7197 - accuracy: 0.7551 - val_loss: 0.8744 - val_accuracy: 0.7727\n",
            "Epoch 62/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 0.7154 - accuracy: 0.7520 - val_loss: 0.8377 - val_accuracy: 0.7773\n",
            "Epoch 63/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.7184 - accuracy: 0.7589 - val_loss: 0.8972 - val_accuracy: 0.7712\n",
            "Epoch 64/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.7052 - accuracy: 0.7580 - val_loss: 0.8928 - val_accuracy: 0.7717\n",
            "Epoch 65/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6880 - accuracy: 0.7656 - val_loss: 0.8795 - val_accuracy: 0.7861\n",
            "Epoch 66/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6885 - accuracy: 0.7613 - val_loss: 0.9085 - val_accuracy: 0.7765\n",
            "Epoch 67/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6732 - accuracy: 0.7682 - val_loss: 0.9208 - val_accuracy: 0.7742\n",
            "Epoch 68/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 0.6774 - accuracy: 0.7701 - val_loss: 0.9078 - val_accuracy: 0.7780\n",
            "Epoch 69/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 0.6693 - accuracy: 0.7717 - val_loss: 0.9127 - val_accuracy: 0.7740\n",
            "Epoch 70/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.6676 - accuracy: 0.7707 - val_loss: 0.9820 - val_accuracy: 0.7768\n",
            "Epoch 71/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.6746 - accuracy: 0.7720 - val_loss: 0.9335 - val_accuracy: 0.7727\n",
            "Epoch 72/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6516 - accuracy: 0.7721 - val_loss: 0.9198 - val_accuracy: 0.7861\n",
            "Epoch 73/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 0.6354 - accuracy: 0.7784 - val_loss: 0.9597 - val_accuracy: 0.7750\n",
            "Epoch 74/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.6417 - accuracy: 0.7770 - val_loss: 0.9291 - val_accuracy: 0.7821\n",
            "Epoch 75/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.6321 - accuracy: 0.7852 - val_loss: 0.9312 - val_accuracy: 0.7813\n",
            "Epoch 76/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6434 - accuracy: 0.7782 - val_loss: 0.9233 - val_accuracy: 0.7798\n",
            "Epoch 77/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6202 - accuracy: 0.7816 - val_loss: 0.9222 - val_accuracy: 0.7823\n",
            "Epoch 78/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6195 - accuracy: 0.7822 - val_loss: 0.9170 - val_accuracy: 0.7811\n",
            "Epoch 79/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6262 - accuracy: 0.7826 - val_loss: 0.9403 - val_accuracy: 0.7829\n",
            "Epoch 80/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6216 - accuracy: 0.7831 - val_loss: 0.9179 - val_accuracy: 0.7775\n",
            "Epoch 81/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.6077 - accuracy: 0.7875 - val_loss: 0.9286 - val_accuracy: 0.7801\n",
            "Epoch 82/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.6120 - accuracy: 0.7828 - val_loss: 0.9116 - val_accuracy: 0.7785\n",
            "Epoch 83/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.5884 - accuracy: 0.7962 - val_loss: 0.9669 - val_accuracy: 0.7750\n",
            "Epoch 84/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.5884 - accuracy: 0.7994 - val_loss: 1.0001 - val_accuracy: 0.7770\n",
            "Epoch 85/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.5914 - accuracy: 0.7945 - val_loss: 0.9513 - val_accuracy: 0.7841\n",
            "Epoch 86/100\n",
            "493/493 [==============================] - 19s 38ms/step - loss: 0.5848 - accuracy: 0.7961 - val_loss: 1.0063 - val_accuracy: 0.7846\n",
            "Epoch 87/100\n",
            "493/493 [==============================] - 19s 39ms/step - loss: 0.5883 - accuracy: 0.7984 - val_loss: 0.9764 - val_accuracy: 0.7829\n",
            "Epoch 88/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5798 - accuracy: 0.8000 - val_loss: 1.0325 - val_accuracy: 0.7808\n",
            "Epoch 89/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.5724 - accuracy: 0.8036 - val_loss: 0.9600 - val_accuracy: 0.7821\n",
            "Epoch 90/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5746 - accuracy: 0.8007 - val_loss: 0.9630 - val_accuracy: 0.7849\n",
            "Epoch 91/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5647 - accuracy: 0.8046 - val_loss: 0.9567 - val_accuracy: 0.7780\n",
            "Epoch 92/100\n",
            "493/493 [==============================] - 18s 36ms/step - loss: 0.5696 - accuracy: 0.8002 - val_loss: 1.0154 - val_accuracy: 0.7818\n",
            "Epoch 93/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5633 - accuracy: 0.8020 - val_loss: 0.9862 - val_accuracy: 0.7813\n",
            "Epoch 94/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.5698 - accuracy: 0.8044 - val_loss: 0.9950 - val_accuracy: 0.7922\n",
            "Epoch 95/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5637 - accuracy: 0.8050 - val_loss: 1.0496 - val_accuracy: 0.7849\n",
            "Epoch 96/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5631 - accuracy: 0.8026 - val_loss: 1.0331 - val_accuracy: 0.7859\n",
            "Epoch 97/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5557 - accuracy: 0.8061 - val_loss: 1.0243 - val_accuracy: 0.7874\n",
            "Epoch 98/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.5487 - accuracy: 0.8099 - val_loss: 1.0023 - val_accuracy: 0.7861\n",
            "Epoch 99/100\n",
            "493/493 [==============================] - 17s 35ms/step - loss: 0.5375 - accuracy: 0.8147 - val_loss: 1.0236 - val_accuracy: 0.7834\n",
            "Epoch 100/100\n",
            "493/493 [==============================] - 18s 37ms/step - loss: 0.5609 - accuracy: 0.8064 - val_loss: 0.9841 - val_accuracy: 0.7897\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d9e9dc10790>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "x = np.expand_dims(x_test[n], axis=0)\n",
        "res = model.predict(x)\n",
        "print( res )\n",
        "print(f'Распознанная буква: {chr(int(np.argmax(res)) + ord(\"А\"))}')\n",
        "\n",
        "plt.imshow(x_test[n], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "BWBW1eHsFjX5",
        "outputId": "e1a55dd7-9886-4dd3-d999-91a831c789ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  7.08293157e-08 1.42659854e-28 0.00000000e+00 0.00000000e+00\n",
            "  1.96556143e-19 0.00000000e+00 1.12091732e-27 1.38688495e-36\n",
            "  2.61771190e-25 1.97711667e-37 2.89244402e-23 6.90089588e-29\n",
            "  0.00000000e+00 0.00000000e+00 9.68234461e-38 0.00000000e+00\n",
            "  2.22153693e-34 0.00000000e+00 4.50574777e-09 0.00000000e+00\n",
            "  5.28706014e-01 4.71282452e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.15175062e-05 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.05017123e-29 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.49222961e-27 0.00000000e+00\n",
            "  5.80046389e-21 0.00000000e+00 3.48743372e-32 0.00000000e+00\n",
            "  3.74921760e-30 2.64147605e-17 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 7.39849840e-29 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            "Распознанная буква: Ш\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}